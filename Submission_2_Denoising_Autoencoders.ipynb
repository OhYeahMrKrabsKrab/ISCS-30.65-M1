{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def apply_median_filter(img):\n",
        "    return cv2.medianBlur(img, 3)\n",
        "\n",
        "def apply_mean_filter(img):\n",
        "    return cv2.blur(img, (3, 3))\n",
        "\n",
        "def apply_gaussian_filter(img):\n",
        "    return cv2.GaussianBlur(img, (3, 3), 0)\n",
        "\n",
        "def apply_bilateral_filter(img):\n",
        "    return cv2.bilateralFilter(img, 5, 75, 75)\n",
        "\n",
        "def get_psnr(original, processed):\n",
        "    mse = np.mean((original - processed) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 255.0\n",
        "    psnr = 10 * np.log10((max_pixel ** 2) / mse)\n",
        "    return psnr\n",
        "\n",
        "def add_poisson(img, lambda_val):\n",
        "  poisson_noise = np.random.poisson(lambda_val, size=img.shape)\n",
        "  noisy_image = img + poisson_noise\n",
        "  if noisy_image.dtype != np.uint8:\n",
        "    noisy_image = cv2.convertScaleAbs(noisy_image)\n",
        "  return noisy_image\n",
        "\n",
        "# Get the images in the pneumonia folder\n",
        "data_folder = \"/content/pneumonia/\"\n",
        "image_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.jpeg')]\n",
        "images = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in image_files]\n",
        "\n",
        "input_size = (124, 124)\n",
        "images_resized = [cv2.resize(img, input_size) for img in images]\n",
        "images_resized = np.array(images_resized)\n",
        "\n",
        "train_images, test_images = train_test_split(images_resized, test_size=0.2, random_state=42)\n",
        "train_images = tf.convert_to_tensor(train_images, dtype=tf.float32)\n",
        "test_images = tf.convert_to_tensor(test_images, dtype=tf.float32)\n",
        "\n",
        "# Autoencoder\n",
        "def create_autoencoder(input_shape, z):\n",
        "    input_img = Input(shape=input_shape)\n",
        "    # Encoder\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(z, (3, 3), activation='relu', padding='same')(x)  # Use latent_dim here\n",
        "    encoded = MaxPooling2D((2, 2), padding='same', name='bottleneck')(x)  # Adding a name to the bottleneck layer\n",
        "    # Decoder\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "lambda_values = [25, 50, 75]\n",
        "noisy_images_list = []\n",
        "for lambda_value in lambda_values:\n",
        "    noisy_images = []\n",
        "    for image in images_resized:\n",
        "        noisy_image = add_poisson(image, lambda_value)\n",
        "        noisy_images.append(noisy_image)\n",
        "    noisy_images_list.append(noisy_images)\n",
        "\n",
        "average_psnr_values = {}\n",
        "input_shape = (124, 124, 1)\n",
        "latent_dim = 32\n",
        "for idx, lambda_value in enumerate(lambda_values):\n",
        "    autoencoder = create_autoencoder(input_shape, latent_dim)  # Create autoencoder with specified input shape and latent dimension\n",
        "    noisy_images = np.array(noisy_images_list[idx])\n",
        "    autoencoder.fit(noisy_images, images_resized, epochs=100, batch_size=10, shuffle=True, validation_split=0.2)\n",
        "\n",
        "    psnr_values_autoencoder = []\n",
        "    psnr_values_median = []\n",
        "    psnr_values_mean = []\n",
        "    psnr_values_gaussian = []\n",
        "    psnr_values_bilateral = []\n",
        "\n",
        "    for test_image in test_images:\n",
        "        denoised_image_autoencoder = autoencoder.predict(test_image[np.newaxis, ...])[0, ...]\n",
        "        psnr_autoencoder = get_psnr(test_image, denoised_image_autoencoder)\n",
        "        psnr_values_autoencoder.append(psnr_autoencoder)\n",
        "\n",
        "        noisy_image = test_image.numpy()\n",
        "        denoised_image_median = apply_median_filter(noisy_image)\n",
        "        denoised_image_mean = apply_mean_filter(noisy_image)\n",
        "        denoised_image_gaussian = apply_gaussian_filter(noisy_image)\n",
        "        denoised_image_bilateral = apply_bilateral_filter(noisy_image)\n",
        "\n",
        "        psnr_median = get_psnr(test_image, denoised_image_median)\n",
        "        psnr_mean = get_psnr(test_image, denoised_image_mean)\n",
        "        psnr_gaussian = get_psnr(test_image, denoised_image_gaussian)\n",
        "        psnr_bilateral = get_psnr(test_image, denoised_image_bilateral)\n",
        "\n",
        "        psnr_values_median.append(psnr_median)\n",
        "        psnr_values_mean.append(psnr_mean)\n",
        "        psnr_values_gaussian.append(psnr_gaussian)\n",
        "        psnr_values_bilateral.append(psnr_bilateral)\n",
        "\n",
        "    average_psnr_values[lambda_value] = {\n",
        "        \"Autoencoder\": np.mean(psnr_values_autoencoder),\n",
        "        \"Median Filter\": np.mean(psnr_values_median),\n",
        "        \"Mean Filter\": np.mean(psnr_values_mean),\n",
        "        \"Gaussian Filter\": np.mean(psnr_values_gaussian),\n",
        "        \"Bilateral Filter\": np.mean(psnr_values_bilateral)\n",
        "    }\n",
        "\n",
        "# Print average PSNR values for each lambda value\n",
        "for lambda_value, psnr_values in average_psnr_values.items():\n",
        "    print(f\"Lambda value: {lambda_value}\")\n",
        "    print(f\"Average PSNR values:\")\n",
        "    for method, average_psnr in psnr_values.items():\n",
        "        print(f\"{method}: {average_psnr:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otMVP-gKo8Tn",
        "outputId": "056a4cce-73ac-4c87-8d46-d22fd9d75574"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 3s 189ms/step - loss: -1065.6849 - val_loss: -1977.9160\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1880.2103 - val_loss: -1986.9363\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0443 - val_loss: -1986.9421\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0481 - val_loss: -1986.9420\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 130ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 176ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 139ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 176ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 176ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 127ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 169ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0488 - val_loss: -1986.9420\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 146ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 148ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 106ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 153ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 129ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 183ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0488 - val_loss: -1986.9420\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 160ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0488 - val_loss: -1986.9420\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 2s 136ms/step - loss: -1756.4744 - val_loss: -1986.7080\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1881.9261 - val_loss: -1986.9150\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0195 - val_loss: -1986.9265\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0320 - val_loss: -1986.9340\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0394 - val_loss: -1986.9395\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0446 - val_loss: -1986.9420\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0471 - val_loss: -1986.9420\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 133ms/step - loss: -1882.0476 - val_loss: -1986.9420\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 163ms/step - loss: -1882.0479 - val_loss: -1986.9420\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0481 - val_loss: -1986.9420\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 125ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 179ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 187ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 160ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 138ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0488 - val_loss: -1986.9420\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 151ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 180ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0488 - val_loss: -1986.9420\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 180ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 127ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 167ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 131ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 154ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 2s 129ms/step - loss: -908.3300 - val_loss: -1985.0234\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1881.6116 - val_loss: -1986.9285\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0339 - val_loss: -1986.9379\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: -1882.0430 - val_loss: -1986.9402\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0463 - val_loss: -1986.9414\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0476 - val_loss: -1986.9414\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 1s 164ms/step - loss: -1882.0479 - val_loss: -1986.9418\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 1s 110ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 1s 177ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 1s 109ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 1s 109ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 1s 177ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9418\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9418\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 1s 175ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 1s 111ms/step - loss: -1882.0485 - val_loss: -1986.9418\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9418\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0481 - val_loss: -1986.9418\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9418\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0482 - val_loss: -1986.9418\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 1s 163ms/step - loss: -1882.0482 - val_loss: -1986.9420\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0481 - val_loss: -1986.9420\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 1s 123ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 1s 121ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0488 - val_loss: -1986.9420\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 1s 177ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 1s 120ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 1s 117ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 1s 122ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 1s 137ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 1s 156ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 1s 118ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 1s 110ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 1s 115ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 1s 161ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 1s 124ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 1s 119ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 1s 116ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 1s 114ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 1s 112ms/step - loss: -1882.0486 - val_loss: -1986.9420\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 1s 113ms/step - loss: -1882.0485 - val_loss: -1986.9420\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Lambda value: 25\n",
            "Average PSNR values:\n",
            "Autoencoder: 5.46\n",
            "Median Filter: 31.23\n",
            "Mean Filter: 30.31\n",
            "Gaussian Filter: 32.23\n",
            "Bilateral Filter: 32.86\n",
            "Lambda value: 50\n",
            "Average PSNR values:\n",
            "Autoencoder: 5.46\n",
            "Median Filter: 31.23\n",
            "Mean Filter: 30.31\n",
            "Gaussian Filter: 32.23\n",
            "Bilateral Filter: 32.86\n",
            "Lambda value: 75\n",
            "Average PSNR values:\n",
            "Autoencoder: 5.46\n",
            "Median Filter: 31.23\n",
            "Mean Filter: 30.31\n",
            "Gaussian Filter: 32.23\n",
            "Bilateral Filter: 32.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lambda = 25 , Lambda = 50, Lambda = 75\n",
        "\n",
        "Median Filter: 31.23, 31.23, 31.23\n",
        "\n",
        "Mean Filter: 30.31, 30.31, 30.31\n",
        "\n",
        "Bilateral Filter: 32.86, 32.86, 32.86\n",
        "\n",
        "Gaussian Filter: 32.23, 32.23, 32.23\n",
        "\n",
        "Autoencoder Model: 5.46, 5.46, 5.46"
      ],
      "metadata": {
        "id": "exnm6uqgwzxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following questions:\n",
        "\n",
        "a) Why is poisson distribution the ideal one to use to simulate noise for medical images? Why not gaussian or something else? Answer in terms of relevance of medical applications.\n",
        "\n",
        "Medical images like X-rays and CT scans can be affected by specks of noise, making it harder to see important details. People can use \"Poisson distribution\" to understand this noise because it mimics how the image is created. This helps them develop better ways to remove the noise, like cleaning the specks off medical images, for better diagnosis and analysis. While other tools exist, they might not be as good at tackling this specific type of noise.\n",
        "\n",
        "b) Which one performed the best? Why do you think this is the case?\n",
        "\n",
        "The average PSNR values indicate that The Bilateral Filter is the best choice for denoising in medical imaging. This could be due to its ability to suppress noise while retaining critical structural details. Its effectiveness in maintaining edge sharpness and fine features results in better images. The filter's adaptability extends to various types and intensities of noise, including common Gaussian noise found in medical images, improving its utility across other imaging scenarios. Its customizable parameters allow for fine-tuning to address specific noise characteristics, offering flexibility and precision in denoising tasks."
      ],
      "metadata": {
        "id": "UKip_yRfMkEy"
      }
    }
  ]
}